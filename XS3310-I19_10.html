<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>XS3310 Teoría Estadística</title>
    <meta charset="utf-8" />
    <meta name="author" content="Prof. Marcela Alfaro Córdoba" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# XS3310 Teoría Estadística
## I Semestre 2019
### Prof. Marcela Alfaro Córdoba
### 3/05/2018 (updated: 2019-05-07)

---





class: center, middle

# ¿Qué hemos visto hasta ahora?

Todo sobre estimadores puntuales + pivotes e intervalos de confianza.

# ¿Qué vamos a discutir hoy?

Bootstrap

---

# Bootstrap

* La inferencia frecuentista se basa en modelos y supuestos. En muchos casos, las expresiones acerca de la exactitud (tales como el error estándar) están basadas en teoría asintótica, y por lo tanto no deberían usarse con muestras pequeñas.

* En otros casos, no estamos usando teoría asintótica, pero no sabemos cómo hacer una suposición acerca de la distribución poblacional, debido a que la muestra no se parece a ninguna forma conocida.

* Una alternativa "moderna" es el método de bootstrap, introducida por Efron así casi 40 años (1979). Bootstrap es un método de remuestreo que es computacionalmente intensivo, y que es aplicable a una gran variedad de casos, incluyendo aquellos en los que los supuestos son más realistas. 

Visualmente:
https://seeing-theory.brown.edu/frequentist-inference/es.html


---

# Bootstrap

¿De dónde viene la expresión?


![](https://img.huffingtonpost.com/asset/5b6b3f1f2000002d00349e9d.jpeg?cache=92vfjlaeaf&amp;ops=scalefit_720_noupscale)

https://www.huffpost.com/entry/pull-yourself-up-by-your-bootstraps-nonsense_n_5b1ed024e4b0bbb7a0e037d4

---

## Ejemplos de bootstrap

### Ejemplo 1: La exactitud de una media muestral.

Tengo datos de sobrevivencia de 16 ratones luego de una cirugía de prueba: hay 9 ratones en el grupo control y 7 ratones en el grupo de tratamiento. 

| Group         | Survival time (in days)      | Mean  |
| ------------- |:----------------------------:| -----:|
| Treatment     | 94,197,16,38,99,141,23       | 86.86 |
| Control       | 52,104,146,10,51,30,40,27,46 | 56.22 |

¿Podemos decir que el tratamiento es efectivo?

En estadística, resolvemos esa pregunta estimando `\(\bar{X}- \bar{Y} = 30.63\)`. El problema es cómo calcular la variabilidad, ¿podemos suponer lo mismo de siempre?
---

## Ejemplos de bootstrap

### Ejemplo 1: La exactitud de una media muestral.

El problema se plantearía de la siguiente manera en teoría estadística: Suponga que una muestra `\(X_1, \dots, X_n\)` es una muestra aleatoria con media `\(\mu\)` y variancia `\(\sigma^2\)`. Entonces, el error estándar de la media muestral es: 

`$$se(\bar{X})= \sqrt(var(\bar{X})) = \frac{\sigma}{\sqrt{n}}$$` 

Esto sugiere que podemos estimar el error estándar con `\(\hat{se}(\bar{X})=\frac{s}{\sqrt{n}}\)`. Y aquí, tenemos dos opciones: la primera utilizar el teorema del límite central (teoría asintótica) o también podemos utilizar el estadístico:

`$$T = \frac{\bar{X}- \bar{Y}}{\sqrt{\hat{se}(\bar{X})^2 + \hat{se}(\bar{Y})^2}}$$`
¿Cuál es el problema? En el caso asintótico, necesitamos de una muestra grande, y en el segundo caso, la distribución de T NO es conocida (podríamos usar la aproximación de Satterhwaite, pero eso sería solo una aproximación).

---

## Ejemplos de bootstrap

### Ejemplo 2: La exactitud de una mediana muestral.

Ahora suponga que queremos comparar las medianas de cada tratamiento, en lugar de las medias. De la tabla anterior podemos calcular:

`\(med(X) = 94, \quad med(Y)=46 \quad \text{y} \quad T'= med(X) - med(Y)= 48\)`

¿Cómo podemos cuantificar la exactitud de las medianas muestrales?

* Teoría Estadística para Medianas muestrales: no existen fórmulas para el error estándar de las medianas muestrales en el caso de muestras pequeñas. 

* Suponga que la distribución `\(P\)` de `\(X_i\)` es continua con densidad `\(p(x)\)`. Entonces, para muestras grandes, la mediana se distribuye aproximadamente como:

`$$med(X) \xrightarrow{d} N(m_p, \frac{\sigma^2}{4np(m_p)})$$`

donde `\(m_P\)` es la mediana de la distribución P.


---

## Ejemplos de bootstrap

### Ejemplo 2: La exactitud de una mediana muestral.

¿Cuál es el(los) problema(s)?

* ¿Son 7 y 9 suficientes observaciones para utilizar una aproximación asintótica?

* Podemos estimar de manera fiable la densidad de p(m_p)?

* ¿Cómo afecta la estimación (asintótica) del error estándar el ancho del intervalo de confianza basado en la aproximación normal?


### Otros ejemplos para ver más adelante: 

* ¿cómo estimar los errores de las estimaciones puntuales hechas con el algoritmo EM o SEM? 
* ¿cómo contrastar hipótesis acerca de si una distribución tiene una o varias modas?

---

# Principios de Bootstrap

* Si no existe información acerca de la distribución, en la muestra observada podemos encontrar información acerca de la distribución subyacente. Por lo tanto, re-muestrear la muestra es la mejor forma de acercarnos a lo que obtendríamos si se pudiera la oportunidad de re-muestrear de la distribución poblacional.

* Suponga que una muestra `\(X = (X_1, \dots, X_n)^T\)` es utilizada para estimar un parámetro `\(\theta\)`. Sea `\(\hat{\theta}= s(X)\)` un estadístico para estimar el parámetro `\(\theta\)`. Para hacer inferencia acerca de `\(\theta\)`, nos interesa la distribución muestral de `\(\hat{\theta}\)`, o ciertos aspectos acerca de esa distribución: la exactitud de nuestra estimación, el intervalo de confianza, etc. En muchas aplicaciones, la distribución muestral de `\(\theta\)` no se puede encontrar.

* Si conociéramos la distribución poblacional `\((F)\)`, podríamos sacar muestras `\(X^{(b)}, b=1,\dots,B\)` de F usando métodos de Monte Carlo para estimar la distribución muestral del estimado. Sin embargo, si `\(F\)` es desconocido, entonces bootstrap sugiere que podemos aproximar ese muestreo re-muestreando nuestra muestra original. Así, podemos encontrar la distribución *empírica* del estimador.

https://seeing-theory.brown.edu/frequentist-inference/es.html

---

# Distribución Empírica

Para una muestra `\(X_1, \dots, X_n\)` de variables aleatorias con valores reales, independientes con distribución P, definimos la distribución \hat{P} como:

`\(P(A) = \frac{1}{n}\sum_{i=1}^{n} 1_A(X_i)\)` para `\(A \subseteq \Re\)`.

`\(\hat{P}\)` es la distribución empírica de la muestra `\(X\)`. \hat{P} puede pensarse como una distribución que pone masa `\(1/n\)` en cada observación X_i (para valores que ocurren más de una vez la masa será un múltiplo de `\(1/n\)`). Entonces, `\(\hat{P}\)` es una distribución de probabilidad discreta con un espacio efectivo de muestreo `\({X_1, \dots, X_n}\)`.

Puede demostrarse que `\(\hat{P}\)` es el estimador máximo verosimil no paramétrico de `\(P\)`, lo cual justifica que podamos estimar `\(P\)` con `\(\hat{P}\)` sin tener otra información acerca de P (como por ejemplo si P pertenece a una familia paramétrica).

---

# Distribución Empírica

## Resultados teóricos

Sea `\(A \subseteq \Re\)` (tal que `\(P(A)\)` está definido), entonces tenemos: `\(\hat{P}(A) \xrightarrow P(A)\)` cuando `\(n \rightarrow \infty\)`.

Este resultado es una consecuencia directa de La Ley de los Grandes Números, ya que:

`$$n \hat{P}(A) = \sum_{i=0}^{n} 1_A(X_i) \sim Bin(n, P(A))$$`

por lo que `\(\hat{P}(A)\)` tiende a su valor esperado `\(P(A)\)` cuando `\(n \rightarrow \infty\)`. Este resultado puede formalizarse mediante:

`$$\sup_{A\in I}|\hat{P}(A)-P(A)| \rightarrow 0 \quad \text{as} \quad n \rightarrow \infty$$` 
donde `\(I\)` es el conjunto de intervalos en `\(\Re\)`. En otras palabras, la distribución P(A) puede ser aproximada por `\(\hat{P}(A)\)` igual de bien para toda `\(A\in I\)`.

---

# Distribución Empírica

## Muestras de una distribución empírica `\(\hat{P}\)`

Suponga que queremos una muestra iid de `\(\hat{P}\)`: `\(X^* = (X^*_1, \dots, X^*_n)^T\)`. Como mencionamos antes, `\(\hat{P}\)` pone masa `\(1/n\)` en cada observación `\(X_i\)`. Entonces, cuando muestreamos de `\(\hat{P}\)`, la observación i-ésima `\(X_i\)` en la muestra original puede ser seleccionada con probabilidad `\(1/n\)`. Esto nos lleva al siguiente proceso:

* Seleccione `\(i_n, \dots, i_n\)` independientemente de una distribución uniforme en `\({1, \dots, n}\)`.

* Ahora haga `\(X^{*}_j = X_{ij}\)` y `\(X^* = (X^*_1, \dots, X^*_n)^T\)`.

En otras palabras, saque una muestra aleatoria con reemplazo de la muestra original `\(X_1, \dots, X_n\)`.

---

# El Principio de Bootstrap

* `\(X = (X_1, \dots, X_n)^T\)` es una muestra aleatoria de una distribución `\(P\)`.

* `\(\theta = t(P)\)` es algún parámetro de la distribución.

* `\(\hat{\theta} = s(X)\)` es un estimador para `\(\theta\)`.

La distribución muestral de `\(\hat{\theta}\)` es entonces estimada por su equivalente de bootstrap:

`$$P(\theta \in A) = P^*(\hat{\theta} \in A)$$`

---

# El Principio de Bootstrap

![Diagrama](BOOT.png)


---

# La aproximación de Monte Carlo

* En algunas ocasiones la forma de la distribución poblacional es conocida, pero la evaluación de la distribución exacta de la distribución muestral no es calculable. 

* El procediento consiste en:

    - Escoja B muestras bootstrap independientes `\(X^{*(1)}, \dots, X^{*(B)}_n\)` de `\(\hat{P}\)`: `\(X_1^{*(b)}, \dots, X^{*(b)}_n \sim_{iid} \hat{P}\)` para `\(b = 1, \dots, B\)`.
    - Evalúe las repeticiones de bootstrap: `\(\hat{\theta}^{*(b)}=s(X^{*(b)})\)`.
    - Estime la distribución muestral de `\(\theta\)` con la distribución empírica de las repeticiones bootstrap: `\(\hat{\theta}^{*(1)}, \dots,\hat{\theta}^{*(B)}\)`:
    
    `$$\hat{P}(\hat{\theta}(A)) = \frac{1}{B}\sum_{b=1}^{B} 1_A(\hat{\theta}^{*(b)})$$` 
    
para conjuntos apropiados de `\(A \subseteq \Re^p\)` (si `\(\hat{\theta} \in \Re^p\)`).

Pero, ¿y si solo queremos una cantidad de esa distribución muestral? pues hay fórmulas para calcularlas directamente.

---

# Bootstrap para calcular errores estándar

Sea `\(\hat{\theta}\)` un estimador de `\(\theta\)` y suponga que queremos conocer el error estándar de `\(\hat{\theta}\)`. Un error estándar estimado de bootstrap se puede obtener con el siguiente algoritmo:

  - Escoja B muestras bootstrap independientes `\(X^{*(1)}, \dots, X^{*(B)}_n\)` de `\(\hat{P}\)`: `\(X_1^{*(b)}, \dots, X^{*(b)}_n \sim_{iid} \hat{P}\)` para `\(b = 1, \dots, B\)`.
  - Evalúe las repeticiones de bootstrap: `\(\hat{\theta}^{*(b)}=s(X^{*(b)})\)`.
  - Estime los errores estándar con la desviación estándar de las B repeticiones:
    
`$$\hat{se}_{boot} = \sqrt{\frac{1}{B-1}\sum_{b=1}^{B}(\hat{\theta}^{*(b)}-\hat{\theta}^{*(.)})}$$`

donde `\(\hat{\theta}^{*(.)} = \frac{1}{B}\sum_{b=1}^{B}\hat{\theta}^{*(b)}\)`.

---

# Bootstrap para calcular el sesgo

Suponga que queremos estimar un parámetro `\(\theta = t(P)\)` con el estadístico `\(\hat{\theta}= s(X)\)`. El sesgo de un estimador `\(\hat{\theta}\)` está definido como:

`$$bias(\hat{\theta})= E(\hat{\theta})-\theta$$` 

Si sustituimos `\(P\)` por la distribución empírica `\(\hat{P}\)`, entonces obtenemos el estimado bootstrap del sesgo:

`$$\hat{bias}(\hat{\theta})= bias^*(\hat{\theta}^*) =  E(\hat{\theta}^*)-\theta^*$$`
donde `\(\theta^* = t(\hat{P})\)`. Note que `\(\hat{\theta}\)` y `\(\theta^*\)` pueden ser diferentes.

---

# Bootstrap para calcular el intervalo de confianza

Si tenemos las repeticiones bootstrap `\(\hat{\theta}^{*(1)}, \dots,\hat{\theta}^{*(B)}\)`, podemos estimar la distribución muestral de `\(\hat{\theta}\)`. A partir de esto, podemos construir intervalos de confianza para `\(\theta\)`. Hay cuatro opciones: IC estándar, IC bootstrap t, IC percentiles, IC percentiles corregido por sesgo.

* IC estándar: Utilizamos el resultado del TLC para decir que `\(\hat{theta}\)` es distribuido aproximadamente normal con media `\(\theta\)` y variancia `\(se(\hat{\theta}^2)\)`. Entonces, un IC `\((1-\alpha)\)` aproximado para `\(\theta\)` está dado por:

`$$\hat{\theta} \pm z_{\alpha/2} \hat{se}_{boot}(\hat{\theta})$$`


---

# Bootstrap para calcular el intervalo de confianza


* IC bootstrap t: Utilizando el mismo resultado anterior, pero ahora usando `\(\hat{se}_X(\hat{\theta})\)` como estimador de `\(se(\hat{\theta})\)` basado en la muestra `\(X\)`. De las muestras bootstrap `\(X^{*(b)}\)` se calcula:

`$$T^{*(b)} = \frac{\hat{\theta}^{*(b)}-\hat{\theta}}{\hat{se}_{X^*}(\hat{\theta})}$$`

De los valores `\(T^{*(b)}\)`, podemos estimar el valor crítico `\(t{\alpha/2}\)` como `\(\hat{t}{\alpha/2}\)` tal que: 

`$$\frac{1}{B} \sum_{b=1}^{B} 1 {[ T^{*(b)} \leq \hat{t}_{\alpha/2} ]} \approx \alpha/2$$`

Entonces: 

`$$\hat{\theta} \pm \hat{t}_{\alpha/2} se(\hat{\theta})$$`

---

# Bootstrap para calcular el intervalo de confianza


* IC percentiles: si solo queremos utilizar los cuantiles empíricos:

`$$\hat{P}^*(\hat{\theta}^* \leq \hat{\theta}_L) = \frac{1}{B} \sum_{b=1}^{B} 1 {[ \hat{\theta}^{*(b)} \leq \hat{\theta}_{L} ]} \approx \alpha/2$$`

`$$\hat{P}^*(\hat{\theta}^* \geq \hat{\theta}_U) = \frac{1}{B} \sum_{b=1}^{B} 1 {[ \hat{\theta}^{*(b)} \geq \hat{\theta}_{U} ]} \approx \alpha/2$$`


* IC percentiles corregido por sesgo. La opción anterior asume que el área debajo de la curva en las dos colas es igual. Si el estimador `\(\hat{\theta}\)` no es la mediana de la distribución bootstrap, entonces esta condición no se cumple. En este caso debemos corregirlo, y hay varias opciones que no serán vistas en esta ocasión.


---

# Ejercicio:

Calcule el error estándar, el sesgo y al menos dos de los intervalos de confianza con los ejemplos 1 y 2 dados al inicio.


# Referencias:

* [UC3M - español](http://halweb.uc3m.es/esp/Personal/personas/jmmarin/esp/Boots/tema1BooPres.pdf)

* [Chicago - inglés](http://galton.uchicago.edu/~eichler/stat24600/Handouts/bootstrap.pdf)

* Efron, B.; Tibshirani, R. (1993). An Introduction to the Bootstrap. Boca Raton, FL: Chapman &amp; Hall/CRC. ISBN 0-412-04231-2.

---
class: center, middle

# ¿Qué discutimos hoy?

Bootstrap: concepto, ejemplos y definiciones. IC utilizando bootstrap

# ¿Qué nos falta para el II Parcial?

Contrastes de hipótesis.


Slides creadas via R package [**xaringan**](https://github.com/yihui/xaringan).
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
