<!DOCTYPE html>
<html>
  <head>
    <title>XS3310 Teoría Estadística</title>
    <meta charset="utf-8">
    <meta name="author" content="Prof. Marcela Alfaro Córdoba" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# XS3310 Teoría Estadística
## I Semestre 2019
### Prof. Marcela Alfaro Córdoba
### 3/05/2018 (updated: 2019-03-14)

---






# ¿Qué vamos a discutir hoy?

* Comentarios de las noticias posteadas.

* Definición de estimadores, algunos ejemplos.

* Repaso de distribuciones muestrales y definiciones de estadísticos de orden.

* ECM y propiedades de los estimadores (introducción). 

* Práctica en grupos.

---

## Algunos conceptos básicos previos
	
a. Muestra Aleatoria

Sean `\(X_{1}, X_{2}, ... , X_{n}\)` un conjunto de variables aleatorias (v.a.) independientes e idénticamente distribuidas; este conjunto se denomina muestra aleatoria de una población infinita.

b. Estadísticos

Es una función de la muestra aleatoria, `\(T=f\left(X_{1}, X_{2}, ... , X_{n}\right)\)`.

NOTA: Un estadístico es a su vez una variable aleatoria y como tal tiene su propia distribución, denominada distribución muestral, con sus parámetros correspondientes. 

c. Estimadores

Cuando un estadístico, llámese `\(\hat{\theta}\)` (theta sombrero), se utiliza para aproximar el valor de un parámetro `\(\theta\)` entonces se acostumbra llamar a ese estadístico con el nombre de estimador.


---

## Estimadores puntuales

Cuando un estadístico, llámese `\(\hat{\theta}\)`, se utiliza para aproximar el valor de un parámetro `\(\theta\)` entonces se acostumbra llamar a ese estadístico con el nombre de *estimador*. Existen dos tipos: estimadores puntuales y estimadores de intervalo. Los segundos los dejaremos para el tema II.

Ejemplos de estimadores puntuales:

1. `\(\bar{X}\)` es estimador de `\(\mu\)`

2. `\(S^2\)` es estimador de `\(\sigma^2\)`

3. `\(\hat{p}\)` es estimador de `\(p\)`

4. `\(\hat{\theta} = \frac{X_{1}+X_{n}}{2}\)` es estimador de `\(\mu\)`


---

## Estimadores


Se pueden tener varios estimadores para un mismo parámetro, entonces la pregunta es, ¿cómo encontramos el mejor estimador?Este buen estimador debe cumplir las siguientes propiedades:

1. Insesgado

2. Eficiente

3. Consistente

4. Suficiente

Antes de entrar en este tema, recordemos 5 teoremas que explican las distribuciones muestrales de las medias y las variancias en poblaciones normales, además de las definiciones de estadísticos de orden.

---

# Repaso

## Distribuciones de medias y variancias muestrales en poblaciones normales

&gt; Teorema 1.1. Si `\(\bar{X}_n\)` es la media muestral de una muestra aleatoria de tamaño `\(n\)` de una distribución normal de media `\(\mu\)` y variancia `\(\sigma^2\)`, entonces `\(\bar{X}_n\)` tiene una distribución normal con media `\(\mu\)` y variancia `\(\sigma^2/n\)`.

Aplicación más común: valores de la tabla z (normal estándar).

Ejemplo: Si `\(X\)` es una variable aleatoria con distribución normal con media 15 y variancia 16. Se toman muestras aleatorias de tamaño 9. Calcular `\(P(12 &lt; \bar{X}_n &lt; 17)\)`.

$$ P(12 &lt; \bar{X}_n &lt; 17) = P(\frac{ 12-15 }{ 4/3 }&lt;Z&lt;\frac{ 17-15 }{ 4/3 }) \\
    = P(-2.25 &lt; Z &lt;1.5) = 0.9210 $$

---

# Repaso

¿Por qué? porque aplicando el teorema 1.1 sabemos que `\(\frac{(\bar{X}_n-\mu)}{\sigma/\sqrt{n}}\)` se distribuye como una normal estándar. ¿De dónde viene la variable `\(Z\)`? Es como se define una v.a. distribuida como `\(N(0,1)\)` y se llama Z porque existe una tabla con valores precalculados para el área debajo de la curva de una `\(N(0,1)\)`. Los valores de la tabla se pueden calcular resolviendo la integral, o simplemente usando un R:


```r
pnorm(1.5,0,1)-pnorm(-2.25,0,1)
```

```
## [1] 0.9209683
```

---

# Repaso


&gt; Teorema 1.2. Si `\(X_1, X_2, ..., X_n\)` es una muestra aleatoria con distribución normal con media `\(\mu\)` y variancia `\(\sigma^2\)`, entonces:

a. `\(\bar{X}\)` y `\(S^2\)` son estocásticamente independientes.

b. La variable `\(U = \frac{(n-1)S^2}{\sigma^2}\)` tiene distribución `\(\chi^2\)` con `\(n-1\)` grados de libertad.

c. La densidad de `\(S^2\)` es la densidad gamma.

La prueba de este teorema está fuera de los contenidos de este curso.

Nota: La parte b se puede usar para probar que `\(Var(S^2) = \frac{2\sigma^4}{n-1}\)` cuando asumimos que `\(X_1, X_2, ..., X_n\)` es una muestra aleatoria con distribución normal con media `\(\mu\)` y variancia `\(\sigma^2\)`.

---

# Repaso

&gt; Teorema 1.3. Si `\(X_1, X_2, ..., X_n\)` es una muestra aleatoria con distribución normal con media `\(\mu\)` y variancia `\(\sigma^2\)`, entonces la variable aleatoria:

$$ t = \frac{ (\bar{ X }-\mu) } { S/\sqrt{ n } } $$

se distribuye como una t de Student con `\(n-1\)` grados de libertad.

Prueba: Por el TLC sabemos que `\(\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\)` se distribuye como una `\(N(0,1)\)`. Por teorema sabemos que `\(U = \frac{(n-1)S^2}{\sigma^2}\)` tiene distribución `\(\chi^2\)` con `\(n-1\)` grados de libertad. Del mismo teorema, sabemos que `\(\bar{X}\)` y `\(S^2\)` son independientes, y por los teorema (vistos en la clase de contínuos), sabemos que la definición de una variable t de Student es `\(Y = \frac{N(0,1)}{\sqrt{\chi^2/k}}\)`. Por todo lo anterior:

$$
\frac{ \frac{ \bar{X}-\mu } { \sigma/\sqrt{ n } } } { \sqrt{ \frac{ (n-1)S^2 } { \sigma^2 }/(n-1) } }=\frac{ \bar{ X }-\mu } { S/\sqrt{ n } }
$$

es una t de Student con `\(n-1\)` grados de libertad.

---

# Repaso


&gt; Teorema 1.4. Si `\(X_1, X_2, ..., X_m\)` es una muestra aleatoria con distribución normal con media `\(\mu_X\)` y variancia `\(\sigma^2_X\)`. Sea `\(Y_1, Y_2, ..., Y_n\)` es una muestra aleatoria con distribución normal con media `\(\mu_Y\)` y variancia `\(\sigma^2_Y\)`. Si ambas poblaciones son independientes entonces: `\(\frac{S^2_X/\sigma^2_X}{S^2_Y/\sigma^2_Y}\)` tiene una distribución `\(F_{m-1, n-1}\)`.

Prueba: Por teorema sabemos que `\(U = \frac{(n-1)S^2}{\sigma^2}\)` tiene distribución `\(\chi^2\)` con `\(n-1\)` grados de libertad. Usando la definición de la distribución F podemos reescribir la división como la división de dos variables distribuidas como `\(\chi^2\)` con distintos grados de libertad:

$$ \frac{ \frac{ (m-1)S^2_X } { \sigma^2_X } } { \frac{ (n-1)S^2_Y } { \sigma^2_Y } } =  \frac{ S^2_X/\sigma^2_X } { S^2_Y/\sigma^2_Y }
$$

---

# Repaso


&gt; Teorema 1.5. Si `\(X_1, X_2, ..., X_m\)` es una muestra aleatoria con distribución normal con media `\(\mu_X\)` y variancia `\(\sigma^2\)`. Sea `\(Y_1, Y_2, ..., Y_n\)` es una muestra aleatoria con distribución normal con media `\(\mu_Y\)` y variancia `\(\sigma^2\)`. Si ambas poblaciones son independientes entonces:

$$ \frac{ (\bar{ X }-\bar{ Y })-(\mu_X-\mu_Y) } { S_p \sqrt{ 1/m+1/n } }$$

se distribuye como una t de Student con (m+n-2) grados de libertad, donde

$$ S_p = \sqrt{ \frac{ (m-1)S^2_X+(n-1)S^2_Y } { m+n-2 } }.$$
---

# Repaso

Prueba: Se sabe que `\(\frac{(\bar{X}-\bar{Y})-(\mu_X-\mu_Y)}{\sigma \sqrt{1/m+1/n}}\)` se distribuye según una `\(N(0,1)\)` ya que `\(\bar{X}\)` es `\(N(\mu_X,\sigma^2/m)\)` y `\(\bar{Y}\)` es `\(N(\mu_Y,\sigma^2/m)\)` y por lo tanto, `\((\bar{X}-\bar{Y})\)` es `\(N(\mu_X-\mu_Y,\sigma^2/m+\sigma^2/n)\)`. Además, `\(\frac{(m-1)S^2_X}{\sigma^2}+\frac{(n-1)S^2_Y}{\sigma^2}\)` es una `\(\chi^2_{(m+n-2)}\)` por teorema. 

Por definición de una variable t de student, el cociente entre la `\(N(0,1)\)` de la parte a) y la raíz cuadrada de la parte b) dividida entre sus grados de libertad, es una t de student con `\(m+n-2\)` grados de libertad. Se se calcula el cociente y se simplifica, se obtiene la variable aleatoria del Teorema.

---

# Repaso

## Estadísticos de orden:

* Supongamos que se tiene una muestra aleatoria de tamaño `\(n\)` de una población infinita que tiene una función de densidad `\(f(x)\)` y función de distribución `\(F(x)\)`. 

* Si los valores de estas variables aleatorias se ordenan de manera que al valor más bajo de las `\(x\)` se le asigna la variable `\(X_{(1)}\)`, al siguiente valor de `\(x\)` se le asigna la variable `\(X_{(2)}\)` y de esta forma se continúa hasta que al mayor valor de `\(x\)` se le asigna la variable `\(X_{(n)}\)`, esto genera un ordenamiento de la muestra aleatoria `\(X_1, X_2, ..., X_n\)` de manera que `\(X_{(1)} &lt; X_{(2)} &lt; ... &lt; X_{(n)}\)`. 

* Estas variables denotan los denominados estadísticos de orden.  De este análisis surge la siguiente pregunta: ¿Cuál es la distribución del estadístico `\(X_{(1)}\)`?

---

# Repaso


&gt; Teorema 1.6. Sea `\(X_1, X_2, ..., X_n\)` una muestra aleatoria de una población infinita con función de densidad `\(f(x)\)` y función de distribución `\(F(x)\)`.  Si `\(X_{(k)}\)` representa el k-ésimo estadístico de orden, entonces la función de densidad de viene dada por:

$$ f(x)= \frac{ n! } { (k-1)!(n-k)! }[F(x)]^{ k-1 }[1-F(x)]^{ n-k }f(x) $$

Nota: En particular se tiene que `\(X_{(1)} = Min\{X_1, X_2, ..., X_n\}\)` y `\(X_{(n)} = Max\{X_1, X_2, ..., X_n\}\)`. Además si `\(n = 2m + 1\)`, la mediana de la muestra corresponde al estadístico de orden `\(X_{(m+1)}\)`.  Si `\(n=2m\)`, la mediana es `\(\frac{1}{2}(X_{m}+X_{m+1})\)`.

&gt; Teorema 1.7. Para `\(n\)` grande, la distribución de muestreo de la mediana para muestras aleatorias de tamaño 2n + 1 es aproximadamente normal con media `\(\mu\)` (mediana poblacional) y variancia `\(\frac{1}{8n[f(\mu)]^2}\)`.

---

## Insesgados + Eficientes + Consistente + Suficientes


![Figura 1. Sesgo y Variancia. Fuente: https://www.slideshare.net/Stratio/lunchlearn-combinacin-de-modelos](./bias.jpg)

Figura 1. Sesgo y Variancia. Fuente: https://www.slideshare.net/Stratio/lunchlearn-combinacin-de-modelos

---

## Ejercicios

1. Se desea estimar la media `\(\mu\)` de una variable aleatoria `\(X\)`. Para ello se toman `\(10\)` datos y se calcula su media muestral `\(\bar{X}\)` y la varianza de dichos datos `\(\sigma^2_X\)`. Comente si son verdaderas o falsas las siguientes afirmaciones:

a) Por el teorema central del límite sabemos que `\(\mu\)` será una variable aleatoria normal.

b) Un estimador de `\(X\)` es `\(\bar{X}\)`.

c) La media muestral con un conjunto de datos es un número y no una variable aleatoria.

d) La media muestral `\(\bar{X}\)` tiene siempre una distribución muestral normal.

e) Si `\(X\)` es normal, `\(\bar{X}\)` es siempre normal.

f) Para disminuir la varianza de `\(\bar{X}\)` a la mitad habría que tomar al menos 100 datos.

g) Como la media muestral es un estimador insesgado, tenemos asegurado que `\(\bar{X} = \mu\)`

---
class: center, middle

# ¿Qué vimos hoy?

Definición de estimadores, algunos ejemplos.

Repaso de distribuciones muestrales y definiciones de estadísticos de orden.

ECM y propiedades de los estimadores (introducción).

# La próxima semana: definiciones y ejemplos


Slides creadas via R package [**xaringan**](https://github.com/yihui/xaringan).

El chakra viene de [remark.js](https://remarkjs.com), [**knitr**](http://yihui.name/knitr), and [R Markdown](https://rmarkdown.rstudio.com).
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
